{{- if .Values.kafka.enabled }}
---
# Headless Service for StatefulSet DNS
apiVersion: v1
kind: Service
metadata:
  name: kafka-headless
  namespace: {{ .Values.global.namespace }}
  labels:
    app: kafka
spec:
  clusterIP: None
  ports:
  - port: {{ .Values.kafka.service.port }}
    name: kafka
  selector:
    app: kafka
---
# Client Service
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: {{ .Values.global.namespace }}
  labels:
    app: kafka
spec:
  type: {{ .Values.kafka.service.type }}
  selector:
    app: kafka
  ports:
  - port: {{ .Values.kafka.service.port }}
    targetPort: {{ .Values.kafka.service.port }}
    {{- if eq .Values.kafka.service.type "NodePort" }}
    nodePort: {{ .Values.kafka.service.nodePort }}
    {{- end }}
    name: kafka
---
# Kafka StatefulSet with Zookeeper
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: {{ .Values.global.namespace }}
  labels:
    app: kafka
spec:
  serviceName: kafka-headless
  replicas: {{ .Values.kafka.replicaCount }}
  selector:
    matchLabels:
      app: kafka
  podManagementPolicy: Parallel
  template:
    metadata:
      labels:
        app: kafka
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9092"
    spec:
      {{- if .Values.securityContext.enabled }}
      securityContext:
        runAsNonRoot: {{ .Values.securityContext.runAsNonRoot }}
        runAsUser: {{ .Values.securityContext.runAsUser }}
        fsGroup: {{ .Values.securityContext.fsGroup }}
        {{- if .Values.securityContext.seccompProfile }}
        seccompProfile:
          type: {{ .Values.securityContext.seccompProfile.type }}
        {{- end }}
      {{- end }}
      {{- if eq .Values.kafka.antiAffinity "hard" }}
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - kafka
            topologyKey: kubernetes.io/hostname
      {{- else if eq .Values.kafka.antiAffinity "soft" }}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - kafka
              topologyKey: kubernetes.io/hostname
      {{- end }}
      containers:
      - name: kafka
        image: {{ .Values.kafka.image.repository }}:{{ .Values.kafka.image.tag }}
        imagePullPolicy: {{ .Values.kafka.image.pullPolicy }}
        command:
        - bash
        - -c
        - |
          # Extract ordinal from hostname (0-based for Kafka)
          export KAFKA_BROKER_ID=${HOSTNAME##*-}
          # Update advertised listeners with actual hostname
          export KAFKA_ADVERTISED_LISTENERS="PLAINTEXT://${HOSTNAME}.kafka-headless.{{ .Values.global.namespace }}.svc.cluster.local:{{ .Values.kafka.service.port }}"
          echo "Starting Kafka Broker ID=${KAFKA_BROKER_ID}"
          /etc/confluent/docker/run
        ports:
        - containerPort: {{ .Values.kafka.service.port }}
          name: kafka
        env:
        # Zookeeper Configuration
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "{{- range $i := until (int .Values.zookeeper.replicaCount) }}zookeeper-{{ $i }}.zookeeper-headless.{{ $.Values.global.namespace }}.svc.cluster.local:2181{{- if ne $i (sub (int $.Values.zookeeper.replicaCount) 1) }},{{- end }}{{- end }}"
        # Listeners configuration
        - name: KAFKA_LISTENERS
          value: "PLAINTEXT://:{{ .Values.kafka.service.port }}"
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: "PLAINTEXT:PLAINTEXT"
        - name: KAFKA_INTER_BROKER_LISTENER_NAME
          value: "PLAINTEXT"
        # Cluster configuration
        - name: KAFKA_DEFAULT_REPLICATION_FACTOR
          value: {{ .Values.kafka.config.defaultReplicationFactor | quote }}
        - name: KAFKA_MIN_INSYNC_REPLICAS
          value: {{ .Values.kafka.config.minInsyncReplicas | quote }}
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: {{ .Values.kafka.config.offsetsTopicReplicationFactor | quote }}
        - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
          value: {{ .Values.kafka.config.defaultReplicationFactor | quote }}
        - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
          value: {{ .Values.kafka.config.minInsyncReplicas | quote }}
        # Performance tuning
        {{- if .Values.kafka.config.numNetworkThreads }}
        - name: KAFKA_NUM_NETWORK_THREADS
          value: {{ .Values.kafka.config.numNetworkThreads | quote }}
        {{- end }}
        {{- if .Values.kafka.config.numIoThreads }}
        - name: KAFKA_NUM_IO_THREADS
          value: {{ .Values.kafka.config.numIoThreads | quote }}
        {{- end }}
        {{- if .Values.kafka.config.socketSendBufferBytes }}
        - name: KAFKA_SOCKET_SEND_BUFFER_BYTES
          value: {{ .Values.kafka.config.socketSendBufferBytes | quote }}
        {{- end }}
        {{- if .Values.kafka.config.socketReceiveBufferBytes }}
        - name: KAFKA_SOCKET_RECEIVE_BUFFER_BYTES
          value: {{ .Values.kafka.config.socketReceiveBufferBytes | quote }}
        {{- end }}
        {{- if .Values.kafka.config.socketRequestMaxBytes }}
        - name: KAFKA_SOCKET_REQUEST_MAX_BYTES
          value: {{ .Values.kafka.config.socketRequestMaxBytes | quote }}
        {{- end }}
        # Retention and compression
        {{- if .Values.kafka.config.logRetentionHours }}
        - name: KAFKA_LOG_RETENTION_HOURS
          value: {{ .Values.kafka.config.logRetentionHours | quote }}
        {{- end }}
        {{- if .Values.kafka.config.logSegmentBytes }}
        - name: KAFKA_LOG_SEGMENT_BYTES
          value: {{ .Values.kafka.config.logSegmentBytes | quote }}
        {{- end }}
        {{- if .Values.kafka.config.compressionType }}
        - name: KAFKA_COMPRESSION_TYPE
          value: {{ .Values.kafka.config.compressionType | quote }}
        {{- end }}
        # Auto create topics
        - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
          value: "true"
        # JVM Options
        {{- if .Values.kafka.jvmOptions }}
        - name: KAFKA_HEAP_OPTS
          value: "-Xms{{ .Values.kafka.jvmOptions.heapSize }} -Xmx{{ .Values.kafka.jvmOptions.maxHeapSize }}"
        {{- end }}
        resources:
          {{- toYaml .Values.kafka.resources | nindent 10 }}
        volumeMounts:
        - name: data
          mountPath: /var/lib/kafka/data
        livenessProbe:
          tcpSocket:
            port: kafka
          initialDelaySeconds: 90
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 6
        readinessProbe:
          tcpSocket:
            port: kafka
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 6
      {{- if not .Values.kafka.persistence.enabled }}
      volumes:
      - name: data
        emptyDir: {}
      {{- end }}
  {{- if .Values.kafka.persistence.enabled }}
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: {{ .Values.kafka.persistence.size }}
      {{- if .Values.kafka.persistence.storageClass }}
      storageClassName: {{ .Values.kafka.persistence.storageClass }}
      {{- end }}
  {{- end }}
{{- if .Values.kafka.podDisruptionBudget.enabled }}
---
# PodDisruptionBudget
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: kafka-pdb
  namespace: {{ .Values.global.namespace }}
spec:
  {{- if .Values.kafka.podDisruptionBudget.minAvailable }}
  minAvailable: {{ .Values.kafka.podDisruptionBudget.minAvailable }}
  {{- end }}
  {{- if .Values.kafka.podDisruptionBudget.maxUnavailable }}
  maxUnavailable: {{ .Values.kafka.podDisruptionBudget.maxUnavailable }}
  {{- end }}
  selector:
    matchLabels:
      app: kafka
{{- end }}
{{- end }}
